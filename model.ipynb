{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prave\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', '.\\\\train_gray.tfrecords',\n",
    "                       \"Directory where train file is present \")\n",
    "\n",
    "tf.app.flags.DEFINE_string('test_dir', '.\\\\test_gray.tfrecords',\n",
    "                       \"Directory where test file is present \")\n",
    "\n",
    "tf.app.flags.DEFINE_string('model_dir', '.\\\\model\\\\',\n",
    "                       \"Directory where model will be saved \")\n",
    "\n",
    "tf.app.flags.DEFINE_string('export_model_dir', '.\\\\export_model\\\\',\n",
    "                       \"Directory where model will be saved for serving \")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('max_steps', 23,\n",
    "                        \"\"\"Number of batches to run.\"\"\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('Btach_size', 25,\n",
    "                        \"batch size\")\n",
    "tf.app.flags.DEFINE_integer('buffer_size', 50,\n",
    "                        \"buffer size\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_classes', 5,\n",
    "                        \"no of classes in dataset\")\n",
    "\n",
    "tf.app.flags.DEFINE_float('learning_rate', 1e-4,\n",
    "                        \"initial learning rate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"image_raw\": tf.FixedLenFeature([], tf.string),\n",
    "        \"label\":     tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    image = tf.decode_raw(parsed[\"image_raw\"], tf.float64)\n",
    "    #image = tf.cast(image, tf.float64)\n",
    "    label = tf.cast(parsed[\"label\"], tf.int64)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(filenames, train, batch_size=FLAGS.Btach_size, buffer_size=FLAGS.buffer_size):\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "    dataset = dataset.map(parser)\n",
    "    \n",
    "    if train:\n",
    "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "        num_repeat = 2\n",
    "    else:\n",
    "        num_repeat = 1\n",
    "    dataset = dataset.repeat(num_repeat)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    images_batch, labels_batch = iterator.get_next()\n",
    "    x = {'image': images_batch}\n",
    "    y = labels_batch\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 62500)\n",
      "[4 4 3 0 4 2 4 3 1 2 2 3 4 0 4 0 2 2 2 0 0 3 3 2 0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x, y =sess.run(input_fn(filenames=FLAGS.train_dir, train=False))\n",
    "\n",
    "print(x[\"image\"].shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(filenames=[FLAGS.train_dir], train=True)\n",
    "\n",
    "def val_input_fn():\n",
    "    return input_fn(filenames=[FLAGS.test_dir],train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    num_classes = FLAGS.num_classes\n",
    "    net = features[\"image\"]\n",
    "    net = tf.identity(net, name=\"input_tensor\")\n",
    "\n",
    "    net = tf.reshape(net, [-1, 250, 250, 1])\n",
    "    \n",
    "    tf.summary.image(\"my_image\", net)\n",
    "\n",
    "    net = tf.identity(net, name=\"input_tensor_after\")\n",
    "\n",
    "    net = tf.layers.conv2d(inputs=net, name='layer_conv1',\n",
    "                           filters=32, kernel_size=3,\n",
    "                           padding='valid', activation=tf.nn.relu)\n",
    "\n",
    "    net = tf.layers.conv2d(inputs=net, name='layer_conv2',\n",
    "                           filters=32, kernel_size=3,\n",
    "                           padding='valid', activation=tf.nn.relu)\n",
    "\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "    \n",
    "    net = tf.layers.dropout(net, rate=0.6, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    \n",
    "\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=1, padding = \"valid\")\n",
    "\n",
    "    net = tf.contrib.layers.flatten(net)\n",
    "\n",
    "    # net = tf.layers.dense(inputs=net, name='layer_fc1',units=1024, activation=tf.nn.relu)\n",
    "    \n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc2',\n",
    "                          units=128, activation=tf.nn.relu)\n",
    "\n",
    "    net = tf.layers.dropout(net, rate=0.6, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc_3',units=num_classes)\n",
    "\n",
    "    logits = net\n",
    "\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "\n",
    "    y_pred = tf.identity(y_pred, name=\"output_pred\")\n",
    "\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "    y_pred_cls = tf.identity(y_pred_cls, name=\"output_cls\")\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions = y_pred_cls,\n",
    "                                          export_outputs = {'predictions': tf.estimator.export.PredictOutput(y_pred_cls)})\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=params[\"learning_rate\"])\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss, global_step=tf.train.get_global_step())\n",
    "        metrics = {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels, y_pred_cls)\n",
    "        }\n",
    "\n",
    "        spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=metrics)\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    receiver_tensor = {'image': tf.placeholder(shape=[None, 250, 250, 1], dtype=tf.float64)}\n",
    "    return tf.estimator.export.ServingInputReceiver(receiver_tensor, receiver_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    config=tf.estimator.RunConfig(\n",
    "        save_checkpoints_steps=30, \n",
    "        save_summary_steps=30,\n",
    "        log_step_count_steps  = 20,\n",
    "        keep_checkpoint_max = 1)\n",
    "    model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                               params={\"learning_rate\": FLAGS.learning_rate},\n",
    "                               model_dir=FLAGS.model_dir,\n",
    "                               config=config)\n",
    "    print(\"---------------------\")\n",
    "    print(\"****traning started*******\")\n",
    "    model.train(input_fn=train_input_fn)\n",
    "    print(\"-------------------\")\n",
    "    print(\"----traning ended---\")\n",
    "    \n",
    "    export_dir = FLAGS.export_model_dir\n",
    "    model.export_savedmodel(export_dir, serving_input_fn)\n",
    "    print(\"-----------------------\")\n",
    "    print(\"*********saving the model for serving******\")\n",
    "    \n",
    "    pre = model.evaluate(input_fn=val_input_fn)\n",
    "    print(pre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '.\\\\model5\\\\', '_tf_random_seed': None, '_save_summary_steps': 30, '_save_checkpoints_steps': 30, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 20, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EC5B9EA320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "---------------------\n",
      "****traning started*******\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into .\\model5\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.826472455147591, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.111985\n",
      "INFO:tensorflow:loss = 0.16614243522279537, step = 21 (178.781 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30 into .\\model5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.127298\n",
      "INFO:tensorflow:loss = 0.14748610896833925, step = 41 (157.378 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41 into .\\model5\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.14748610896833925.\n",
      "-------------------\n",
      "----traning ended---\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predictions', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from .\\model5\\model.ckpt-41\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: .\\export_model5\\temp-b'1539926721'\\saved_model.pb\n",
      "-----------------------\n",
      "*********saving the model for serving******\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-19-05:25:30\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from .\\model5\\model.ckpt-41\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-19-05:25:38\n",
      "INFO:tensorflow:Saving dict for global step 41: accuracy = 0.98245615, global_step = 41, loss = 0.07120811\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 41: .\\model5\\model.ckpt-41\n",
      "{'accuracy': 0.98245615, 'loss': 0.07120811, 'global_step': 41}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ],
     "output_type": "error"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prave\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run(main=main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
